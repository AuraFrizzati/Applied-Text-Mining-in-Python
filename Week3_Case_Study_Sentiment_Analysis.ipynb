{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "Week3_Case-Study_Sentiment-Analysis.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AuraFrizzati/Applied-Text-Mining-in-Python/blob/main/Week3_Case_Study_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBoWDfMgIAlv"
      },
      "source": [
        "---\n",
        "\n",
        "_You are currently looking at **version 1.0** of this notebook. To download notebooks and datafiles, as well as get help on Jupyter notebooks in the Coursera platform, visit the [Jupyter Notebook FAQ](https://www.coursera.org/learn/python-text-mining/resources/d9pwm) course resource._\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_si-HmCIAlz"
      },
      "source": [
        "*Note: Some of the cells in this notebook are computationally expensive. To reduce runtime, this notebook is using a subset of the data.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_LqzuSTIAlz"
      },
      "source": [
        "# Case Study: Sentiment Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ngt9zAXLIAl0"
      },
      "source": [
        "### Data Prep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-KfRFJteIAl0",
        "outputId": "a41dc6ec-6de1-41fd-e41d-f7101b2cf010"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Read in the data\n",
        "df = pd.read_csv('Amazon_Unlocked_Mobile.csv')\n",
        "\n",
        "# Sample the data to speed up computation\n",
        "# Comment out this line to match with lecture\n",
        "df = df.sample(frac=0.1, random_state=10)\n",
        "\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Product Name</th>\n",
              "      <th>Brand Name</th>\n",
              "      <th>Price</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Review Votes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>394349</th>\n",
              "      <td>Sony XPERIA Z2 D6503 FACTORY UNLOCKED Internat...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>244.95</td>\n",
              "      <td>5</td>\n",
              "      <td>Very good one! Better than Samsung S and iphon...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34377</th>\n",
              "      <td>Apple iPhone 5c 8GB (Pink) - Verizon Wireless</td>\n",
              "      <td>Apple</td>\n",
              "      <td>194.99</td>\n",
              "      <td>1</td>\n",
              "      <td>The phone needed a SIM card, would have been n...</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248521</th>\n",
              "      <td>Motorola Droid RAZR MAXX XT912 M Verizon Smart...</td>\n",
              "      <td>Motorola</td>\n",
              "      <td>174.99</td>\n",
              "      <td>5</td>\n",
              "      <td>I was 3 months away from my upgrade and my Str...</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167661</th>\n",
              "      <td>CNPGD [U.S. Office Extended Warranty] Smartwat...</td>\n",
              "      <td>CNPGD</td>\n",
              "      <td>49.99</td>\n",
              "      <td>1</td>\n",
              "      <td>an experience i want to forget</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73287</th>\n",
              "      <td>Apple iPhone 7 Unlocked Phone 256 GB - US Vers...</td>\n",
              "      <td>Apple</td>\n",
              "      <td>922.00</td>\n",
              "      <td>5</td>\n",
              "      <td>GREAT PHONE WORK ACCORDING MY EXPECTATIONS.</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Product Name Brand Name   Price  \\\n",
              "394349  Sony XPERIA Z2 D6503 FACTORY UNLOCKED Internat...        NaN  244.95   \n",
              "34377       Apple iPhone 5c 8GB (Pink) - Verizon Wireless      Apple  194.99   \n",
              "248521  Motorola Droid RAZR MAXX XT912 M Verizon Smart...   Motorola  174.99   \n",
              "167661  CNPGD [U.S. Office Extended Warranty] Smartwat...      CNPGD   49.99   \n",
              "73287   Apple iPhone 7 Unlocked Phone 256 GB - US Vers...      Apple  922.00   \n",
              "\n",
              "        Rating                                            Reviews  \\\n",
              "394349       5  Very good one! Better than Samsung S and iphon...   \n",
              "34377        1  The phone needed a SIM card, would have been n...   \n",
              "248521       5  I was 3 months away from my upgrade and my Str...   \n",
              "167661       1                     an experience i want to forget   \n",
              "73287        5        GREAT PHONE WORK ACCORDING MY EXPECTATIONS.   \n",
              "\n",
              "        Review Votes  \n",
              "394349           0.0  \n",
              "34377            1.0  \n",
              "248521           3.0  \n",
              "167661           0.0  \n",
              "73287            1.0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkbNBXi4IAl2",
        "outputId": "bb52c82c-9303-4133-963b-6ab35bb7231e"
      },
      "source": [
        "# Drop missing values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Remove any 'neutral' ratings equal to 3\n",
        "df = df[df['Rating'] != 3]\n",
        "\n",
        "# Encode 4s and 5s as 1 (rated positively)\n",
        "# Encode 1s and 2s as 0 (rated poorly)\n",
        "df['Positively Rated'] = np.where(df['Rating'] > 3, 1, 0)\n",
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Product Name</th>\n",
              "      <th>Brand Name</th>\n",
              "      <th>Price</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Reviews</th>\n",
              "      <th>Review Votes</th>\n",
              "      <th>Positively Rated</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>34377</th>\n",
              "      <td>Apple iPhone 5c 8GB (Pink) - Verizon Wireless</td>\n",
              "      <td>Apple</td>\n",
              "      <td>194.99</td>\n",
              "      <td>1</td>\n",
              "      <td>The phone needed a SIM card, would have been n...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248521</th>\n",
              "      <td>Motorola Droid RAZR MAXX XT912 M Verizon Smart...</td>\n",
              "      <td>Motorola</td>\n",
              "      <td>174.99</td>\n",
              "      <td>5</td>\n",
              "      <td>I was 3 months away from my upgrade and my Str...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167661</th>\n",
              "      <td>CNPGD [U.S. Office Extended Warranty] Smartwat...</td>\n",
              "      <td>CNPGD</td>\n",
              "      <td>49.99</td>\n",
              "      <td>1</td>\n",
              "      <td>an experience i want to forget</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73287</th>\n",
              "      <td>Apple iPhone 7 Unlocked Phone 256 GB - US Vers...</td>\n",
              "      <td>Apple</td>\n",
              "      <td>922.00</td>\n",
              "      <td>5</td>\n",
              "      <td>GREAT PHONE WORK ACCORDING MY EXPECTATIONS.</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>277158</th>\n",
              "      <td>Nokia N8 Unlocked GSM Touch Screen Phone Featu...</td>\n",
              "      <td>Nokia</td>\n",
              "      <td>95.00</td>\n",
              "      <td>5</td>\n",
              "      <td>I fell in love with this phone because it did ...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100311</th>\n",
              "      <td>Blackberry Torch 2 9810 Unlocked Phone with 1....</td>\n",
              "      <td>BlackBerry</td>\n",
              "      <td>77.49</td>\n",
              "      <td>5</td>\n",
              "      <td>I am pleased with this Blackberry phone! The p...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251669</th>\n",
              "      <td>Motorola Moto E (1st Generation) - Black - 4 G...</td>\n",
              "      <td>Motorola</td>\n",
              "      <td>89.99</td>\n",
              "      <td>5</td>\n",
              "      <td>Great product, best value for money smartphone...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>279878</th>\n",
              "      <td>OtterBox 77-29864 Defender Series Hybrid Case ...</td>\n",
              "      <td>OtterBox</td>\n",
              "      <td>9.99</td>\n",
              "      <td>5</td>\n",
              "      <td>I've bought 3 no problems. Fast delivery.</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>406017</th>\n",
              "      <td>Verizon HTC Rezound 4G Android Smarphone - 8MP...</td>\n",
              "      <td>HTC</td>\n",
              "      <td>74.99</td>\n",
              "      <td>4</td>\n",
              "      <td>Great phone for the price...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302567</th>\n",
              "      <td>RCA M1 Unlocked Cell Phone, Dual Sim, 5Mp Came...</td>\n",
              "      <td>RCA</td>\n",
              "      <td>159.99</td>\n",
              "      <td>5</td>\n",
              "      <td>My mom is not good with new technoloy but this...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             Product Name  Brand Name   Price  \\\n",
              "34377       Apple iPhone 5c 8GB (Pink) - Verizon Wireless       Apple  194.99   \n",
              "248521  Motorola Droid RAZR MAXX XT912 M Verizon Smart...    Motorola  174.99   \n",
              "167661  CNPGD [U.S. Office Extended Warranty] Smartwat...       CNPGD   49.99   \n",
              "73287   Apple iPhone 7 Unlocked Phone 256 GB - US Vers...       Apple  922.00   \n",
              "277158  Nokia N8 Unlocked GSM Touch Screen Phone Featu...       Nokia   95.00   \n",
              "100311  Blackberry Torch 2 9810 Unlocked Phone with 1....  BlackBerry   77.49   \n",
              "251669  Motorola Moto E (1st Generation) - Black - 4 G...    Motorola   89.99   \n",
              "279878  OtterBox 77-29864 Defender Series Hybrid Case ...    OtterBox    9.99   \n",
              "406017  Verizon HTC Rezound 4G Android Smarphone - 8MP...         HTC   74.99   \n",
              "302567  RCA M1 Unlocked Cell Phone, Dual Sim, 5Mp Came...         RCA  159.99   \n",
              "\n",
              "        Rating                                            Reviews  \\\n",
              "34377        1  The phone needed a SIM card, would have been n...   \n",
              "248521       5  I was 3 months away from my upgrade and my Str...   \n",
              "167661       1                     an experience i want to forget   \n",
              "73287        5        GREAT PHONE WORK ACCORDING MY EXPECTATIONS.   \n",
              "277158       5  I fell in love with this phone because it did ...   \n",
              "100311       5  I am pleased with this Blackberry phone! The p...   \n",
              "251669       5  Great product, best value for money smartphone...   \n",
              "279878       5          I've bought 3 no problems. Fast delivery.   \n",
              "406017       4                       Great phone for the price...   \n",
              "302567       5  My mom is not good with new technoloy but this...   \n",
              "\n",
              "        Review Votes  Positively Rated  \n",
              "34377            1.0                 0  \n",
              "248521           3.0                 1  \n",
              "167661           0.0                 0  \n",
              "73287            1.0                 1  \n",
              "277158           0.0                 1  \n",
              "100311           0.0                 1  \n",
              "251669           0.0                 1  \n",
              "279878           0.0                 1  \n",
              "406017           0.0                 1  \n",
              "302567           4.0                 1  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6trCHG2nIAl2",
        "outputId": "f55c6927-0017-40f5-bed2-37420557cdef"
      },
      "source": [
        "# Most ratings are positive\n",
        "df['Positively Rated'].mean() ## the outcome classes are unbalanced"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7471776686078667"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yN12pXU5IAl3"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['Reviews'], #train data\n",
        "                                                    df['Positively Rated'], #train labels\n",
        "                                                    random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p28SLIaUIAl3",
        "outputId": "23eb18c7-36d1-47f9-9138-6b5339585058"
      },
      "source": [
        "print('X_train first entry:\\n\\n', X_train.iloc[0])\n",
        "print('\\n\\nX_train shape: ', X_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train first entry:\n",
            "\n",
            " Everything about it is awesome!\n",
            "\n",
            "\n",
            "X_train shape:  (23052,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5t1pq_bIAl4",
        "outputId": "d856b1a3-8ab6-4d09-b421-97e3020dd5c3"
      },
      "source": [
        "print('\\n','Number training samples = ', len(X_train), '\\n',\n",
        "     'Number test samples = ', len(X_test))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " Number training samples =  23052 \n",
            " Number test samples =  7685\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUV7DfXLIAl4"
      },
      "source": [
        "- The review **text feature** needs to be **converted** into a **numeric format** that scikit-learn can use. The **bag-of-words approach** is a simple and commonly used way to represent text for use in ML. It **ignores text structure** and only **counts how often each word occurs**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FT9xu56GIAl4"
      },
      "source": [
        "# CountVectorizer\n",
        "\n",
        "- CountVectorizer allows us to use the **bag-of-word approach** by **converting** a **collection of text documents** into a **matrix of token counts**. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ls45reOeIAl4",
        "outputId": "f7f2feb7-73bd-44fb-a5e0-4a32d383ccc9"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Fit the CountVectorizer to the training data\n",
        "vect = CountVectorizer().fit(X_train)\n",
        "vect"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CountVectorizer()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4HsNMQRIAl5"
      },
      "source": [
        "- **Fitting** the **CountVectorizer tokenizes each document** by finding **all sequences of characters** (at least 2 letters/numbers) separated by word boundaries. It then **converts everything to lowercase** and **build a vocabulary** using these tokens. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_W8otv5lIAl5",
        "outputId": "3458e0d9-5078-4327-ba17-af28200ea260"
      },
      "source": [
        "vect.get_feature_names()[::2000]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['00',\n",
              " 'arroja',\n",
              " 'comapa√±ias',\n",
              " 'dvds',\n",
              " 'golden',\n",
              " 'lands',\n",
              " 'oil',\n",
              " 'razonable',\n",
              " 'smallsliver',\n",
              " 'tweak']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oo5Nt0VOIAl5",
        "outputId": "434b3dd9-1a2d-470c-8089-738de12bdc64"
      },
      "source": [
        "len(vect.get_feature_names()) ## length of the vocabulary"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19601"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EgP59J3dIAl6"
      },
      "source": [
        "#print(vect.vocabulary_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A5WiWBSWIAl6",
        "outputId": "80c4aa2d-d485-49bc-e6f2-9f3200374955"
      },
      "source": [
        "# transform the documents in the training data to a document-term matrix\n",
        "X_train_vectorized = vect.transform(X_train) ## this is to create the bag-of-word representation of x_train\n",
        "\n",
        "## the text data is now stored in a sparse matrix where each row corresponds to a text document\n",
        "## and each column to a training vocabulary item/word:\n",
        "print(X_train_vectorized)\n",
        "X_train_vectorized ## this gives the representation of the sparse matrix: \"\"(row, col) non-zero value\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 1063)\t1\n",
            "  (0, 2262)\t1\n",
            "  (0, 6631)\t1\n",
            "  (0, 9555)\t1\n",
            "  (0, 9582)\t1\n",
            "  (1, 296)\t1\n",
            "  (1, 298)\t1\n",
            "  (1, 1457)\t1\n",
            "  (1, 1574)\t1\n",
            "  (1, 1698)\t4\n",
            "  (1, 2022)\t2\n",
            "  (1, 2320)\t1\n",
            "  (1, 2572)\t1\n",
            "  (1, 2654)\t1\n",
            "  (1, 2906)\t2\n",
            "  (1, 2951)\t1\n",
            "  (1, 3019)\t1\n",
            "  (1, 3203)\t2\n",
            "  (1, 3306)\t1\n",
            "  (1, 3308)\t1\n",
            "  (1, 4813)\t1\n",
            "  (1, 5416)\t1\n",
            "  (1, 5725)\t1\n",
            "  (1, 5779)\t1\n",
            "  (1, 5914)\t1\n",
            "  :\t:\n",
            "  (23050, 19424)\t1\n",
            "  (23050, 19488)\t18\n",
            "  (23050, 19496)\t4\n",
            "  (23050, 19502)\t2\n",
            "  (23050, 19529)\t2\n",
            "  (23050, 19532)\t1\n",
            "  (23051, 446)\t1\n",
            "  (23051, 1698)\t1\n",
            "  (23051, 6351)\t1\n",
            "  (23051, 7058)\t1\n",
            "  (23051, 7576)\t1\n",
            "  (23051, 9582)\t3\n",
            "  (23051, 10312)\t1\n",
            "  (23051, 11950)\t1\n",
            "  (23051, 12360)\t1\n",
            "  (23051, 12800)\t2\n",
            "  (23051, 14676)\t1\n",
            "  (23051, 15693)\t1\n",
            "  (23051, 17333)\t1\n",
            "  (23051, 17343)\t2\n",
            "  (23051, 18334)\t1\n",
            "  (23051, 18884)\t1\n",
            "  (23051, 19057)\t1\n",
            "  (23051, 19205)\t1\n",
            "  (23051, 19285)\t1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<23052x19601 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 613289 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtHHQj5kIAl6",
        "outputId": "6e525a88-6cfc-41ca-e67c-13f3dc5b15f8"
      },
      "source": [
        "## The entries in this matrix are the number of times each word appears in each document.\n",
        "## Because the number of words in the vocabulary is much larger than the number of words that\n",
        "## might appear in a single review, most entries of this matrix are 0 (sparse matrix).\n",
        "\n",
        "print(X_train_vectorized.toarray())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5ZHWHdIIAl7",
        "outputId": "ac760ce7-53b9-453e-a397-2fe00659e399"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Train the model\n",
        "model = LogisticRegression()  ## LR works well for high-dimensional sparse data\n",
        "model.fit(X_train_vectorized, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/Users/aurafrizzati/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bo4wcj4KIAl7",
        "outputId": "0044b336-8215-4898-b95b-e0cbe2772a50"
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Predict the transformed test documents\n",
        "\n",
        "## The X_test matrix gets transformed using the same Vectorizer that was fitted to the training data:\n",
        "## any word in X_test that does not appear in X_train will just be ignored\n",
        "predictions = model.predict(vect.transform(X_test)) \n",
        "print('AUC: ', roc_auc_score(y_test, predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.8963986165184588\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "_2I64Le8IAl7",
        "outputId": "9b08eb31-bf11-400d-8a8c-491a1c50a86e"
      },
      "source": [
        "# get the feature names as numpy array\n",
        "feature_names = np.array(vect.get_feature_names())\n",
        "\n",
        "# Sort the coefficients from the model\n",
        "sorted_coef_index = model.coef_[0].argsort()\n",
        "\n",
        "# Find the 10 smallest and 10 largest coefficients\n",
        "# The 10 largest coefficients are being indexed using [:-11:-1] \n",
        "# so the list returned is in order of largest to smallest\n",
        "print('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
        "print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Smallest Coefs:\n",
            "['worst' 'terrible' 'slow' 'junk' 'waste' 'sucks' 'poor' 'useless'\n",
            " 'disappointed' 'horrible']\n",
            "\n",
            "Largest Coefs: \n",
            "['excelent' 'excellent' 'excelente' 'perfectly' 'love' 'perfect' 'exactly'\n",
            " 'great' 'best' 'awesome']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b68LKPijIAl8"
      },
      "source": [
        "# Tf-idf (Term Frequency - Inverse Document Frequency)\n",
        "- This is an alternative approach to CountVectorizer and it allows to **rescale features**, weighing them on the basis of how important they are for a document: **higher weight** is given to **words that appear often in the document** but **not in the rest of the corpus**.\n",
        "- **Words** with **low Tf-Idf** are either \n",
        "    - **commonly used in all documents** \n",
        "    - or **rarely used** and occur only in **long documents**\n",
        "- **Words** with **high Tf-Idf** are **frequently used within specific documents** but **rarely used across all documents**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IkljcddIAl9",
        "outputId": "ceeafea4-9047-4b34-f788-dc6d25730446"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "## TfidfVectorizer goes through the same initial process as CountVectorizer of tokenizing the document, \n",
        "## we can expect to obtain the same number of features. However, we can reduce the number by specifying\n",
        "## min_df = min number of documents in which the word needs to abbear to become part of the vocabulary.\n",
        "\n",
        "# Fit the TfidfVectorizer to the training data specifiying a minimum document frequency of 5\n",
        "vect = TfidfVectorizer(min_df=5).fit(X_train) ## minimum appearence of each word in at least 5 documents\n",
        "len(vect.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5442"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdvhfNN-IAl-",
        "outputId": "f231da10-b330-435c-e26e-6939aa05a2dc"
      },
      "source": [
        "X_train_vectorized = vect.transform(X_train)\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_vectorized, y_train)\n",
        "\n",
        "predictions = model.predict(vect.transform(X_test))\n",
        "\n",
        "print('AUC: ', roc_auc_score(y_test, predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.889951006492175\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOmB8vXOIAl-",
        "outputId": "e387eef5-369f-4438-d473-11c7a5526383"
      },
      "source": [
        "feature_names = np.array(vect.get_feature_names())\n",
        "\n",
        "sorted_tfidf_index = X_train_vectorized.max(0).toarray()[0].argsort()\n",
        "\n",
        "print('Smallest tfidf:\\n{}\\n'.format(feature_names[sorted_tfidf_index[:10]]))\n",
        "print('Largest tfidf: \\n{}'.format(feature_names[sorted_tfidf_index[:-11:-1]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Smallest tfidf:\n",
            "['61' 'printer' 'approach' 'adjustment' 'consequences' 'length' 'emailing'\n",
            " 'degrees' 'handsfree' 'chipset']\n",
            "\n",
            "Largest tfidf: \n",
            "['unlocked' 'handy' 'useless' 'cheat' 'up' 'original' 'exelent' 'exelente'\n",
            " 'exellent' 'satisfied']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JMbWVQQIAl_",
        "outputId": "3fb67294-cc77-4c70-849f-e28119fb8189"
      },
      "source": [
        "sorted_coef_index = model.coef_[0].argsort()\n",
        "\n",
        "print('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
        "print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Smallest Coefs:\n",
            "['not' 'slow' 'disappointed' 'worst' 'terrible' 'never' 'return' 'doesn'\n",
            " 'horrible' 'waste']\n",
            "\n",
            "Largest Coefs: \n",
            "['great' 'love' 'excellent' 'good' 'best' 'perfect' 'price' 'awesome'\n",
            " 'far' 'perfectly']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChVUwfnkIAl_"
      },
      "source": [
        "- One **problem** with the **common Bag-of-words approach** is that **word order is disregarded**:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NH-3OloQIAl_",
        "outputId": "5d520aee-ffbb-4ded-8abb-58bbd0dfe08e"
      },
      "source": [
        "# These reviews are treated the same by our current model\n",
        "print(model.predict(vect.transform(['not an issue, phone is working',\n",
        "                                    'an issue, phone is not working'])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApLZVPs6IAmE"
      },
      "source": [
        "- One way around this issue is to **add some context** by adding **sequences of word features** known as **n-grams**:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEKZ426XIAmE"
      },
      "source": [
        "# n-grams\n",
        "- To **create n-gram features**, we can pass a tuple to `ngram_range` **parameter** of `CountVectorizer` (minimum length of sequence, maximum length of sequence)\n",
        "- Although **n-grams** can be powerful in capture meaning, **longer sequences** can cause an **explosion in the number of features**!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7vnCY8bIAmE",
        "outputId": "8514bd93-5f07-45b9-ffea-8a19630ea158"
      },
      "source": [
        "# Fit the CountVectorizer to the training data specifiying a minimum \n",
        "# document frequency of 5 and extracting 1-grams and 2-grams\n",
        "\n",
        "## n-grams include single words and bigrams\n",
        "vect = CountVectorizer(min_df=5, ngram_range=(1,2)).fit(X_train) \n",
        "X_train_vectorized = vect.transform(X_train)\n",
        "\n",
        "print(X_train_vectorized)\n",
        "len(vect.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  (0, 386)\t1\n",
            "  (0, 418)\t1\n",
            "  (0, 2970)\t1\n",
            "  (0, 7664)\t1\n",
            "  (0, 7665)\t1\n",
            "  (0, 11769)\t1\n",
            "  (0, 11805)\t1\n",
            "  (0, 12244)\t1\n",
            "  (0, 12460)\t1\n",
            "  (1, 125)\t1\n",
            "  (1, 126)\t1\n",
            "  (1, 129)\t1\n",
            "  (1, 131)\t1\n",
            "  (1, 995)\t1\n",
            "  (1, 1352)\t4\n",
            "  (1, 1696)\t1\n",
            "  (1, 1947)\t1\n",
            "  (1, 1953)\t2\n",
            "  (1, 2596)\t2\n",
            "  (1, 2635)\t1\n",
            "  (1, 2996)\t1\n",
            "  (1, 3033)\t1\n",
            "  (1, 3566)\t1\n",
            "  (1, 3567)\t1\n",
            "  (1, 3665)\t1\n",
            "  :\t:\n",
            "  (23051, 8976)\t1\n",
            "  (23051, 12244)\t3\n",
            "  (23051, 12692)\t1\n",
            "  (23051, 12718)\t1\n",
            "  (23051, 13693)\t1\n",
            "  (23051, 16440)\t1\n",
            "  (23051, 16583)\t1\n",
            "  (23051, 17736)\t1\n",
            "  (23051, 17738)\t1\n",
            "  (23051, 18055)\t2\n",
            "  (23051, 18244)\t1\n",
            "  (23051, 18456)\t1\n",
            "  (23051, 20265)\t1\n",
            "  (23051, 21394)\t1\n",
            "  (23051, 23186)\t1\n",
            "  (23051, 23402)\t2\n",
            "  (23051, 23990)\t2\n",
            "  (23051, 26193)\t1\n",
            "  (23051, 26209)\t1\n",
            "  (23051, 26942)\t1\n",
            "  (23051, 27615)\t1\n",
            "  (23051, 27649)\t1\n",
            "  (23051, 28295)\t1\n",
            "  (23051, 28468)\t1\n",
            "  (23051, 28480)\t1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29072"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jy4dmZ55IAmF",
        "outputId": "89fdc7eb-c71d-4cc6-94f5-ce6cacba2ab5"
      },
      "source": [
        "model = LogisticRegression()\n",
        "model.fit(X_train_vectorized, y_train)\n",
        "\n",
        "predictions = model.predict(vect.transform(X_test))\n",
        "\n",
        "print('AUC: ', roc_auc_score(y_test, predictions))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/Users/aurafrizzati/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "AUC:  0.9104640361714084\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvo_JnzLIAmF",
        "outputId": "8c486a80-605b-4493-9f31-8bb0edb4de89"
      },
      "source": [
        "feature_names = np.array(vect.get_feature_names())\n",
        "\n",
        "sorted_coef_index = model.coef_[0].argsort()\n",
        "\n",
        "print('Smallest Coefs:\\n{}\\n'.format(feature_names[sorted_coef_index[:10]]))\n",
        "print('Largest Coefs: \\n{}'.format(feature_names[sorted_coef_index[:-11:-1]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Smallest Coefs:\n",
            "['no good' 'junk' 'poor' 'slow' 'worst' 'broken' 'not good' 'terrible'\n",
            " 'defective' 'horrible']\n",
            "\n",
            "Largest Coefs: \n",
            "['excellent' 'excelente' 'perfect' 'excelent' 'great' 'love' 'awesome'\n",
            " 'no problems' 'good' 'best']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1meAFOUIAmF",
        "outputId": "4c962a4b-314a-424f-f4d8-f809559b1825"
      },
      "source": [
        "# These reviews are now correctly identified\n",
        "print(model.predict(vect.transform(['not an issue, phone is working',\n",
        "                                    'an issue, phone is not working'])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-68_c2uCIAmF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}